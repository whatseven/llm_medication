import json
import sys
import os
import time
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))
sys.path.insert(0, project_root)

from main_textgrad import medical_diagnosis_pipeline

def load_dataset(file_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½RJUAæ•°æ®é›†"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return [json.loads(line.strip()) for line in f if line.strip()]

def parse_disease_labels(disease_str: str) -> List[str]:
    """è§£æç–¾ç—…æ ‡ç­¾å­—ç¬¦ä¸²ï¼ŒæŒ‰ä¸­æ–‡æ ‡ç‚¹ç¬¦å·åˆ†å‰²"""
    if not disease_str:
        return []
    diseases = re.split(r'[ã€ï¼Œ,;ï¼›/\s]+', disease_str.strip())
    return [d.strip() for d in diseases if d.strip()]

def extract_diseases_from_diagnosis(diagnosis_text: str) -> List[str]:
    """ä»è¯Šæ–­ç»“æœä¸­æå–ç–¾ç—…åç§°"""
    try:
        # æŸ¥æ‰¾<final_diagnosis>æ ‡ç­¾
        pattern = r'<final_diagnosis>\s*(\{.*?\})\s*</final_diagnosis>'
        match = re.search(pattern, diagnosis_text, re.DOTALL)
        
        if match:
            diagnosis_data = json.loads(match.group(1))
            diseases = diagnosis_data.get('diseases', [])
            return diseases if isinstance(diseases, list) else [diseases]
        
        # å¤‡é€‰æå–æ¨¡å¼
        for pattern in [r'è¯Šæ–­[ï¼š:]\s*([^ã€‚\n]+)', r'å¯èƒ½çš„ç–¾ç—…[ï¼š:]\s*([^ã€‚\n]+)', 
                       r'åˆæ­¥è¯Šæ–­[ï¼š:]\s*([^ã€‚\n]+)', r'è€ƒè™‘[ï¼š:]?\s*([^ã€‚\nï¼Œ,]+)']:
            matches = re.findall(pattern, diagnosis_text)
            if matches:
                return [match.strip() for match in matches]
        
        return ["æœªèƒ½æå–ç–¾ç—…ä¿¡æ¯"]
    except Exception as e:
        return [f"æå–é”™è¯¯: {str(e)}"]

def process_single_item(item: Dict[str, Any], disease_list_file: str = None, use_context: bool = False) -> Dict[str, Any]:
    """å¤„ç†å•ä¸ªæ•°æ®é¡¹"""
    try:
        # é¢„å¤„ç†è¾“å…¥
        if use_context:
            input_text = f"æ‚£è€…é—®é¢˜ï¼š{item['question']}\n\nç›¸å…³åŒ»å­¦çŸ¥è¯†ï¼š\n{item['context']}"
        else:
            input_text = item['question']
        
        # è§£æçœŸå®ç–¾ç—…æ ‡ç­¾
        ground_truth_diseases = parse_disease_labels(item['disease'])
        
        # è°ƒç”¨è¯Šæ–­æµç¨‹
        start_time = time.time()
        diagnosis_result = medical_diagnosis_pipeline(input_text, disease_list_file=disease_list_file, silent_mode=True)
        end_time = time.time()
        
        # æå–é¢„æµ‹ç–¾ç—…ä¿¡æ¯
        predicted_diseases = extract_diseases_from_diagnosis(diagnosis_result)
        
        result = {
            'id': item['id'],
            'ground_truth_disease': ground_truth_diseases,
            'ground_truth_answer': item['answer'],
            'ground_truth_advice': item['advice'],
            'input_text': input_text,
            'raw_diagnosis': diagnosis_result,
            'predicted_diseases': predicted_diseases,
            'processing_time': round(end_time - start_time, 2),
            'status': 'success',
            'use_context': use_context
        }
        
        print(f"âœ“ å®ŒæˆID {item['id']}: {predicted_diseases} vs {ground_truth_diseases}")
        return result
        
    except Exception as e:
        print(f"âœ— ID {item['id']} å¤„ç†å¤±è´¥: {str(e)}")
        return {
            'id': item['id'],
            'ground_truth_disease': parse_disease_labels(item['disease']),
            'input_text': item['question'],
            'raw_diagnosis': f"å¤„ç†é”™è¯¯: {str(e)}",
            'predicted_diseases': ["å¤„ç†å¤±è´¥"],
            'processing_time': 0,
            'status': 'error',
            'use_context': use_context
        }

def evaluate_dataset(input_file: str, output_file: str, max_workers: int = 100, 
                    limit: int = None, disease_list_file: str = None, use_context: bool = False):
    """è¯„ä¼°æ•´ä¸ªRJUAæ•°æ®é›†"""
    print(f"å¼€å§‹è¯„ä¼°RJUAæ•°æ®é›†: {os.path.basename(input_file)}")
    print(f"è¾“å…¥æ¨¡å¼: {'é—®é¢˜+çŸ¥è¯†èƒŒæ™¯' if use_context else 'ä»…é—®é¢˜'}")
    print(f"ç–¾ç—…åˆ—è¡¨çº¦æŸ: {'æ˜¯' if disease_list_file else 'å¦'}")
    
    # åŠ è½½æ•°æ®é›†
    dataset = load_dataset(input_file)
    if limit:
        dataset = dataset[:limit]
    print(f"å¤„ç†æ•°æ®: {len(dataset)} æ¡")
    
    # å¹¶å‘å¤„ç†
    start_time = time.time()
    results = []
    completed_count = 0
    total_count = len(dataset)
    
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_item = {
            executor.submit(process_single_item, item, disease_list_file, use_context): item 
            for item in dataset
        }
        
        for future in as_completed(future_to_item):
            results.append(future.result())
            completed_count += 1
            
            # æ¯å®Œæˆ5ä¸ªæ ·æœ¬æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if completed_count % 5 == 0 or completed_count == total_count:
                elapsed_time = time.time() - start_time
                avg_time_per_item = elapsed_time / completed_count
                remaining_items = total_count - completed_count
                estimated_remaining_time = avg_time_per_item * remaining_items
                
                print(f"ğŸ“Š è¿›åº¦: {completed_count}/{total_count} ({completed_count/total_count*100:.1f}%)")
                print(f"â±ï¸  å·²ç”¨æ—¶: {elapsed_time/60:.1f}åˆ†é’Ÿ, é¢„è®¡å‰©ä½™: {estimated_remaining_time/60:.1f}åˆ†é’Ÿ")
                print("=" * 50)
    
    # æ’åºå¹¶ç»Ÿè®¡
    results.sort(key=lambda x: int(x['id']))
    total_time = round(time.time() - start_time, 2)
    success_count = sum(1 for r in results if r['status'] == 'success')
    
    print(f"\nå¤„ç†å®Œæˆ! æ€»è€—æ—¶: {total_time}ç§’, æˆåŠŸ: {success_count}/{len(results)}")
    
    # ç®€å•å‡†ç¡®ç‡åˆ†æ
    if success_count > 0:
        correct = sum(1 for r in results if r['status'] == 'success' and 
                     set(r['predicted_diseases']) & set(r['ground_truth_disease']))
        accuracy = correct / success_count
        print(f"ç®€å•å‡†ç¡®ç‡: {accuracy:.4f} ({correct}/{success_count})")
    
    # ä¿å­˜ç»“æœ
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w', encoding='utf-8') as f:
        for result in results:
            f.write(json.dumps(result, ensure_ascii=False) + '\n')
    
    print(f"ç»“æœä¿å­˜åˆ°: {output_file}")
    return results

def simple_accuracy_analysis(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """ç®€å•çš„å‡†ç¡®ç‡åˆ†æ"""
    total = len(results)
    success_results = [r for r in results if r['status'] == 'success']
    success_count = len(success_results)
    
    if success_count == 0:
        return {
            'total': total,
            'success_count': 0,
            'error_count': total,
            'accuracy': 0.0
        }
    
    # é›†åˆåŒ¹é…ï¼šé¢„æµ‹ç–¾ç—…ä¸çœŸå®ç–¾ç—…æœ‰äº¤é›†å³è®¤ä¸ºæ­£ç¡®
    correct_predictions = 0
    for result in success_results:
        predicted = set(result['predicted_diseases'])
        ground_truth = set(result['ground_truth_disease'])
        
        # å¦‚æœæœ‰äº¤é›†ï¼Œè®¤ä¸ºé¢„æµ‹æ­£ç¡®
        if predicted & ground_truth:
            correct_predictions += 1
    
    accuracy = correct_predictions / success_count if success_count > 0 else 0.0
    
    return {
        'total': total,
        'success_count': success_count,
        'error_count': total - success_count,
        'correct_predictions': correct_predictions,
        'accuracy': round(accuracy, 4)
    }

if __name__ == "__main__":
    # ==================== é…ç½®å‚æ•°åŒºåŸŸ ====================
    # è¾“å…¥æ•°æ®é›†æ–‡ä»¶è·¯å¾„
    input_file = "/home/ubuntu/ZJQ/llm_medication/llm_medication/src/data/RJUA_CN/RJUA_test.json"
    
    # è¾“å‡ºç›®å½•å’Œæ–‡ä»¶å
    output_dir = "/home/ubuntu/ZJQ/llm_medication/llm_medication/src/data/result/RJUACN"
    output_file = os.path.join(output_dir, "evaluation_results4.jsonl")
    
    # ç–¾ç—…åˆ—è¡¨æ–‡ä»¶è·¯å¾„é…ç½®ï¼ˆå¯é€‰ï¼‰
    # è®¾ç½®ä¸º None è¡¨ç¤ºä¸ä½¿ç”¨ç–¾ç—…åˆ—è¡¨çº¦æŸ
    # è®¾ç½®ä¸ºæ–‡ä»¶è·¯å¾„è¡¨ç¤ºä½¿ç”¨ç–¾ç—…åˆ—è¡¨çº¦æŸ
    disease_list_file ="/home/ubuntu/ZJQ/llm_medication/llm_medication/src/data/RJUA_CN/disease.txt"  # é»˜è®¤ä¸ä½¿ç”¨ç–¾ç—…åˆ—è¡¨çº¦æŸ
    # disease_list_file = "/home/ubuntu/ZJQ/llm_medication/llm_medication/src/data/RJUA_CN/disease.txt"  # ä½¿ç”¨ç–¾ç—…åˆ—è¡¨çº¦æŸ
    
    # è¾“å…¥æ¨¡å¼é…ç½®
    use_context = False  # False: ä»…ä½¿ç”¨é—®é¢˜, True: ä½¿ç”¨é—®é¢˜+çŸ¥è¯†èƒŒæ™¯
    # ====================================================
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # è¿è¡Œè¯„ä¼°
    print("=== RJUAä¸­æ–‡æ•°æ®é›†è¯„ä¼° ===")
    choice = input("é€‰æ‹©æ¨¡å¼:\n1. æµ‹è¯•æ¨¡å¼(å‰10æ¡)\n2. å°æ‰¹é‡(å‰50æ¡)\n3. å…¨é‡è¯„ä¼°\nè¯·é€‰æ‹©(1/2/3): ").strip()
    
    if choice == '1':
        limit = 10
        max_workers = 2  # å‡å°‘å¹¶å‘æ•°
        print("âš ï¸  æµ‹è¯•æ¨¡å¼ï¼šæ¯ä¸ªæ ·æœ¬éœ€çº¦11æ¬¡LLMè°ƒç”¨ï¼Œé¢„è®¡éœ€è¦2-5åˆ†é’Ÿ")
    elif choice == '2':
        limit = 50
        max_workers = 2  # å‡å°‘å¹¶å‘æ•°
        print("âš ï¸  å°æ‰¹é‡æ¨¡å¼ï¼šé¢„è®¡éœ€è¦15-30åˆ†é’Ÿ")
    elif choice == '3':
        limit = None
        max_workers = 10  # è¿›ä¸€æ­¥å‡å°‘å¹¶å‘æ•°ï¼Œå› ä¸ºæ¯ä¸ªæ ·æœ¬è°ƒç”¨æ›´å¤š
        print("âš ï¸  å…¨é‡è¯„ä¼°ï¼š213ä¸ªæ ·æœ¬ï¼Œé¢„è®¡éœ€è¦1.5-3å°æ—¶ï¼")
        confirm = input("ç¡®è®¤è¦è¿›è¡Œå…¨é‡è¯„ä¼°å—ï¼Ÿ(y/N): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆè¯„ä¼°")
            exit(0)
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨æµ‹è¯•æ¨¡å¼")
        limit = 10
        max_workers = 2
    
    # æ‰§è¡Œè¯„ä¼°
    results = evaluate_dataset(input_file, output_file, max_workers, limit, disease_list_file, use_context)
    
    # ç®€å•åˆ†æ
    print("\n=== ç®€å•å‡†ç¡®ç‡åˆ†æ ===")
    analysis = simple_accuracy_analysis(results)
    for key, value in analysis.items():
        print(f"{key}: {value}")
    
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
